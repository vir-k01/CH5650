{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH5650:Unsupervised_Classify.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzNz6tc2uCk9X1+LrClaFR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vir-k01/CH5650/blob/main/CH5650_Unsupervised_Classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification of crystals (in the form of 2D Diffraction fingerprints) using Unsupervised Learning\n",
        "-Authored by Vir Karan"
      ],
      "metadata": {
        "id": "HwB_KdjWEnrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the required packages and dataset"
      ],
      "metadata": {
        "id": "csyXuWpPE4gh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EfnMNiIOC-le"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras import layers\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.cluster import KMeans\n",
        "from itertools import permutations\n",
        "from multiprocessing import Pool\n",
        "import pickle\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm loading the dataset from my google drive, hence the below cell. Data can be downloaded from:\n",
        "\n",
        "Pristine dataset (Diffraction fingerprints of crystals): https://dataverse.harvard.edu/api/access/datafile/3238702?format=original\n",
        "\n",
        "Pristine dataset (Labels of crystals): https://dataverse.harvard.edu/api/access/datafile/3238704?format=original\n",
        "\n",
        "Dataset info: https://dataverse.harvard.edu/api/access/datafile/3238706?format=original\n",
        "\n",
        "Defected dataset (Diffraction fingerprints of defected crystals): https://dataverse.harvard.edu/api/access/datafile/3238702?format=original\n",
        "\n",
        "Defected dataset (Labels of defected crystals): https://dataverse.harvard.edu/api/access/datafile/3238704?format=original\n",
        "\n",
        "Dataset is in the form of pickled files, have to open them and convert to numpy arrays."
      ],
      "metadata": {
        "id": "x55IBu4gE-Cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "X = pickle.load(open('/content/drive/MyDrive/Acads/CH5650/pristine_dataset_x.pkl', 'rb'), encoding='latin1')\n",
        "y = pickle.load(open('/content/drive/MyDrive/Acads/CH5650/pristine_dataset_y.pkl', 'rb'), encoding='latin1')\n",
        "X_val = pickle.load(open('/content/drive/MyDrive/Acads/CH5650/pristine_dataset_x_val.pkl', 'rb'), encoding='latin1')\n",
        "y_val = pickle.load(open('/content/drive/MyDrive/Acads/CH5650/pristine_dataset_y_val.pkl', 'rb'), encoding='latin1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH43aW8IE_GU",
        "outputId": "b2dd778b-9ab1-4c5b-e1ef-99ae0fd6f17a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and train a simple autoencoder (architecture and hyperparameters are given in the report). Then, use K-Means to cluster the reduced order representation of the dataset. In this case, we'll iterate over several possible dimensions for the bottleneck layer (as given in the list \"dims\"). This is because, unlike PCA, we cannot get a direct plot between captured features and number of components (dimensions) to choose the number of components to keep. So, the model that gives the best results will be kept."
      ],
      "metadata": {
        "id": "-7qPKj9zFCLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dims = [2, 4, 8, 32] # This is the size of our encoded representations\n",
        "\n",
        "acc = []\n",
        "perms = []\n",
        "\n",
        "for encoding_dim in dims:\n",
        "  # This is our input image\n",
        "  input_img = keras.Input(shape=(64*64*3,))\n",
        "  e1 = layers.Dense(128, activation='relu')(input_img)\n",
        "  e2 = layers.Dense(64, activation='relu')(e1)\n",
        "  # \"encoded\" is the encoded representation of the input\n",
        "  encoded = layers.Dense(encoding_dim, activation='relu')(e2)\n",
        "  d1 = layers.Dense(64, activation='relu')(encoded)\n",
        "  d2 = layers.Dense(128, activation='relu')(d1)\n",
        "  # \"decoded\" is the lossy reconstruction of the input\n",
        "  decoded = layers.Dense(64*64*3, activation='tanh')(d2)\n",
        "\n",
        "  # This model maps an input to its reconstruction\n",
        "  autoencoder = keras.Model(input_img, decoded)\n",
        "  encoder = keras.Model(input_img, encoded) #This model maps an input to its learnt reduced order representation\n",
        "  #Compile and train the autoencoder\n",
        "  autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  autoencoder.fit(X.reshape(10517, -1), X.reshape(10517, -1), epochs=10, validation_split=0.05)\n",
        "\n",
        "  #use K-means to cluster the reduced order representation of the dataset\n",
        "  enc = encoder.predict(X.reshape(10517, -1))\n",
        "  kmeans = KMeans(n_clusters=7, init='random')\n",
        "  kmeans.fit(enc)\n",
        "\n",
        "  #plot the results\n",
        "  plt.scatter(enc[:, 0], enc[:, 1], c=kmeans.predict(enc), cmap='jet')\n",
        "  plt.ylabel('Encoding Dim 2')\n",
        "  plt.xlabel('Encoding Dim 1')\n",
        "  plt.title('Actual data with labels')\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "\n",
        "  plt.scatter(enc[:, 0], enc[:, 1], c=y, cmap='jet')\n",
        "  plt.ylabel('Encoding Dim 2')\n",
        "  plt.xlabel('Encoding Dim 1')\n",
        "  plt.title('Data with labels predicted by KMeans')\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "\n",
        "  #Next we can iterate over all possible permutations of the labels in the k-means clustering\n",
        "  #and get the labels with best accuracy \n",
        "  indices = []\n",
        "\n",
        "  def euklidean_distance(a, b):\n",
        "      return np.sqrt(((a - b) ** 2).sum())\n",
        "\n",
        "  for x in enc:\n",
        "      distances = np.array([euklidean_distance(x, centroid) for centroid in kmeans.cluster_centers_])\n",
        "      indices.append(np.argmin(distances))\n",
        "      \n",
        "      \n",
        "  def validate(permutation):\n",
        "      correct_predictions = 0\n",
        "      for index, y in zip(indices, y_val):\n",
        "          if y == permutation[index]:\n",
        "              correct_predictions += 1\n",
        "      return correct_predictions / len(y_val)\n",
        "      \n",
        "\n",
        "  def search_for_best_permutation(permutations):\n",
        "      best_permutation = None\n",
        "      highest_accuracy = 0\n",
        "      for index, p in enumerate(permutations):\n",
        "          accuracy = validate(p)\n",
        "          if accuracy > highest_accuracy:\n",
        "              best_permutation = p\n",
        "              highest_accuracy = accuracy\n",
        "      return highest_accuracy, best_permutation\n",
        "    \n",
        "\n",
        "  permutations = list(permutations(range(7)))\n",
        "\n",
        "  slices = np.array(range(17))*(int(len(permutations)/16))\n",
        "  p = []\n",
        "  for index, item in enumerate(slices):\n",
        "      try:\n",
        "          p += [permutations[item:slices[index+1]]]\n",
        "      except:\n",
        "          pass\n",
        "          \n",
        "  with Pool(16) as pool:\n",
        "      results = pool.map(search_for_best_permutation, p)\n",
        "\n",
        "  best_permutation = None\n",
        "  highest_accuracy = 0\n",
        "\n",
        "  for accuracy, permutation in results:\n",
        "      if accuracy > highest_accuracy:\n",
        "          best_permutation = permutation\n",
        "          highest_accuracy = accuracy\n",
        "  acc.append(highest_accuracy)\n",
        "  perms.append(best_permutation)\n",
        "  print('Dim: '+ str(encoding_dim))\n",
        "  print('Best_permutation: ' + str(best_permutation))\n",
        "  print('Accuracy: '+ str(highest_accuracy))"
      ],
      "metadata": {
        "id": "7V37uvGVDaTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, try the same procedure as above but with Linear PCA. Here, select the top 50 components to keep (based on scree plot)."
      ],
      "metadata": {
        "id": "y0IRNkAWGj7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(100)\n",
        "pca.fit(X.reshape(10517, -1))\n",
        "X_ =  pca.transform(X.reshape(10517, -1))\n",
        "\n",
        "kmeans = KMeans(n_clusters=7, init='random')\n",
        "kmeans.fit(X_[:, :50])\n",
        "\n",
        "indices = []\n",
        "\n",
        "def euklidean_distance(a, b):\n",
        "    return np.sqrt(((a - b) ** 2).sum())\n",
        "\n",
        "for x in X_[:, :50]:\n",
        "    distances = np.array([euklidean_distance(x, centroid) for centroid in kmeans.cluster_centers_])\n",
        "    indices.append(np.argmin(distances))\n",
        "    \n",
        "    \n",
        "def validate(permutation):\n",
        "    correct_predictions = 0\n",
        "    for index, y in zip(indices, y_val):\n",
        "        if y == permutation[index]:\n",
        "            correct_predictions += 1\n",
        "    return correct_predictions / len(y_val)\n",
        "    \n",
        "\n",
        "def search_for_best_permutation(permutations):\n",
        "    best_permutation = None\n",
        "    highest_accuracy = 0\n",
        "    for index, p in enumerate(permutations):\n",
        "        accuracy = validate(p)\n",
        "        if accuracy > highest_accuracy:\n",
        "            best_permutation = p\n",
        "            highest_accuracy = accuracy\n",
        "    return highest_accuracy, best_permutation\n",
        "  \n",
        "\n",
        "permutations = list(permutations(range(7)))\n",
        "\n",
        "slices = np.array(range(17))*(int(len(permutations)/16))\n",
        "p = []\n",
        "for index, item in enumerate(slices):\n",
        "    try:\n",
        "        p += [permutations[item:slices[index+1]]]\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "with Pool(16) as pool:\n",
        "    results = pool.map(search_for_best_permutation, p)\n",
        "\n",
        "best_permutation = None\n",
        "highest_accuracy = 0\n",
        "\n",
        "for accuracy, permutation in results:\n",
        "    if accuracy > highest_accuracy:\n",
        "        best_permutation = permutation\n",
        "        highest_accuracy = accuracy\n",
        "\n",
        "print('Best_permutation: ' + str(best_permutation))\n",
        "print('Accuracy: '+ str(highest_accuracy))\n",
        "\n",
        "out = kmeans.predict(X_[:, :50])\n",
        "label_map = {0: best_permutation[0], 1: best_permutation[1], 2: best_permutation[2], 3: best_permutation[3], 4: best_permutation[4], 5: best_permutation[5], 6: best_permutation[6]}\n",
        "lab = [label_map[e] for e in y]\n",
        "\n",
        "plt.scatter(X_[:, 0], X_[:, 1], c=y, cmap='jet')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('Data with actual labels')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.scatter(X_[:, 0], X_[:, 1], c=out, cmap='jet')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('Data with KMeans predicted labels')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NY5ki5GvEUQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, try out Kernel PCA (with a polynomial kernel) as well."
      ],
      "metadata": {
        "id": "fs7_mK_FGxc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kpca = KernelPCA(100, kernel='poly')\n",
        "kpca.fit(X.reshape(10517, -1))\n",
        "X_k =  kpca.transform(X.reshape(10517, -1))\n",
        "\n",
        "kmeans = KMeans(n_clusters=7, init='random')\n",
        "kmeans.fit(X_k[:, :50])\n",
        "\n",
        "indices = []\n",
        "\n",
        "def euklidean_distance(a, b):\n",
        "    return np.sqrt(((a - b) ** 2).sum())\n",
        "\n",
        "for x in X_k[:, :50]:\n",
        "    distances = np.array([euklidean_distance(x, centroid) for centroid in kmeans.cluster_centers_])\n",
        "    indices.append(np.argmin(distances))\n",
        "    \n",
        "    \n",
        "def validate(permutation):\n",
        "    correct_predictions = 0\n",
        "    for index, y in zip(indices, y_val):\n",
        "        if y == permutation[index]:\n",
        "            correct_predictions += 1\n",
        "    return correct_predictions / len(y_val)\n",
        "    \n",
        "\n",
        "def search_for_best_permutation(permutations):\n",
        "    best_permutation = None\n",
        "    highest_accuracy = 0\n",
        "    for index, p in enumerate(permutations):\n",
        "        accuracy = validate(p)\n",
        "        if accuracy > highest_accuracy:\n",
        "            best_permutation = p\n",
        "            highest_accuracy = accuracy\n",
        "    return highest_accuracy, best_permutation\n",
        "  \n",
        "\n",
        "permutations = list(permutations(range(7)))\n",
        "\n",
        "slices = np.array(range(17))*(int(len(permutations)/16))\n",
        "p = []\n",
        "for index, item in enumerate(slices):\n",
        "    try:\n",
        "        p += [permutations[item:slices[index+1]]]\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "with Pool(16) as pool:\n",
        "    results = pool.map(search_for_best_permutation, p)\n",
        "\n",
        "best_permutation = None\n",
        "highest_accuracy = 0\n",
        "\n",
        "for accuracy, permutation in results:\n",
        "    if accuracy > highest_accuracy:\n",
        "        best_permutation = permutation\n",
        "        highest_accuracy = accuracy\n",
        "\n",
        "print('Best_permutation: ' + str(best_permutation))\n",
        "print('Accuracy: '+ str(highest_accuracy))\n",
        "\n",
        "out = kmeans.predict(X_[:, :50])\n",
        "label_map = {0: best_permutation[0], 1: best_permutation[1], 2: best_permutation[2], 3: best_permutation[3], 4: best_permutation[4], 5: best_permutation[5], 6: best_permutation[6]}\n",
        "lab = [label_map[e] for e in y]\n",
        "\n",
        "plt.scatter(X_k[:, 0], X_k[:, 1], c=y, cmap='jet')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('Data with actual labels')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.scatter(X_k[:, 0], X_k[:, 1], c=out, cmap='jet')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('Data with KMeans predicted labels')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EFNgAZupEXQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}